---
title: "Jasen_Regularization"
author: "Jasen Zhang"
date: "11/21/2020"
output: pdf_document
---

# 1 Loading the Data

```{r echo=FALSE}
library(tidyverse)
library(gridExtra)
library(gplots)
library(glmnet)
library(grid)

dir = getwd()
data_dir <- paste('df_imp.RData', sep = '')
load(data_dir)

response_vars <- c('TARGET_deathRate')

df <- df_imp4 %>% select(- c('ID', 'incidenceRate'))


response_vars <- c('TARGET_deathRate')
vars <- colnames(df)
vars_1 <- setdiff(vars, response_vars)
predict_vars <- paste(vars_1, collapse = ' + ')

df <- data.frame(sapply(df, as.numeric))
```


# 2 Splitting Test and Training Set

## Arbitrarily chose 10% to be test set

```{r message=FALSE}
set.seed(221)
test_set_index <- sample(1:nrow(df), floor(nrow(df))/10)
train_set_index <- setdiff(1:nrow(df), test_set_index)

test <- df[test_set_index,]
train <- df[train_set_index,]

test_y <- test %>% select(response_vars)
test_x <- test %>% select(vars_1)
train_y <- train %>% select(response_vars)
train_x <- train %>% select(vars_1)
```

# 3. Lasso Cross Validation, 10 folds since that's default

```{r}

lambda_seq <- 10^seq(-4, -1.95, by = .025)
set.seed(221)
cv_output <- cv.glmnet(as.matrix(train_x), as.matrix(train_y),
                       alpha = 1, lambda = lambda_seq)

best_lambda <- cv_output$lambda.min

best_lambda

lasso_best <- glmnet(as.matrix(train_x), as.matrix(train_y), alpha = 1, lambda = best_lambda)

pred_test_y <- predict(lasso_best, s = best_lambda, newx = as.matrix(test_x))
pred_train_y <- predict(lasso_best, s = best_lambda, newx = as.matrix(train_x))

```

# 3.5 Plotting Graph of Hyperparameter

```{r}
cv_error <- cv_output$cvm
lambdas <- cv_output$lambda
hyper <- data.frame(lambdas, cv_error)

# taking the minimum
min_cv_error <- min(hyper$cv_error)
min_df <- hyper %>% filter(cv_error == min_cv_error)

grob <- grobTree(textGrob("(a)", x=0.01,  y=0.97, hjust=0,
  gp=gpar(fontsize=13)))


g_lasso_hyper <- ggplot() + geom_point(data = hyper, aes(x = lambdas, y = cv_error)) + 
  geom_point(data = min_df, aes(x = lambdas, y = cv_error), color = 'red') + 
  scale_x_continuous(trans = 'log10') + 
  ylab('Mean Cross-Validation Error') + 
  xlab('Lambda') + 
  annotation_custom(grob)

g_lasso_hyper
```

# 4 Plotting Y_hat vs Y for training set

```{r}
train_results <- data.frame(train_y, pred_train_y)
colnames(train_results) <- c('y_true', 'y_hat')
R_squared <- as.numeric(unname(cor(train_y, pred_train_y)))
r_squared_lasso_train <- R_squared
R_squared <- sprintf("%.3f", round(R_squared,3))
R_squared_label <- paste('R^2 = ', R_squared)
rmse_lasso_train <- sqrt(sum((train_results$y_true - train_results$y_hat)^2)/nrow(train_results))

grob <- grobTree(textGrob("(b)", x=0.01,  y=0.97, hjust=0,
  gp=gpar(fontsize=13)))

g_lasso_train <- ggplot(train_results) + 
  geom_point(aes(x = y_true, y= y_hat)) + 
  geom_line(aes(x = y_true, y = y_true), color = 'red') + 
  ylab('Predicted Cancer Death Rate') + 
  xlab('True Cancer Death Rate') + 
  annotation_custom(grob)

g_lasso_train
```



# 5 Plotting Y_hat vs Y for test set

```{r}
test_results <- data.frame(test_y, pred_test_y)
colnames(test_results) <- c('y_true', 'y_hat')
R_squared <- as.numeric(unname(cor(test_y, pred_test_y)))
r_squared_lasso_test <- R_squared
R_squared <- sprintf("%.3f", round(R_squared,3))
R_squared_label <- paste('R^2 = ', R_squared)
rmse_lasso_test <- sqrt(sum((test_results$y_true - test_results$y_hat)^2)/nrow(test_results))

grob <- grobTree(textGrob("(c)", x=0.01,  y=0.97, hjust=0,
  gp=gpar(fontsize=13)))

g_lasso_test <- ggplot(test_results) + 
  geom_point(aes(x = y_true, y= y_hat)) + 
  geom_line(aes(x = y_true, y = y_true), color = 'red')  +
  ylab('Predicted Cancer Death Rate') + 
  xlab('True Cancer Death Rate') + 
  annotation_custom(grob)

g_lasso_test
```
# 6. Beta hats

```{r}
lasso_beta_hat <- as.numeric(lasso_best$beta)
lasso_var_names <- rownames(lasso_best$beta)

lasso_final_df <- data.frame(lasso_coeffs = lasso_beta_hat)
rownames(lasso_final_df) = lasso_var_names
```


